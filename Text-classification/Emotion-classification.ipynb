{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/cgrandhi/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/cgrandhi/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('text_emotion.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>author</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1956967341</td>\n",
       "      <td>empty</td>\n",
       "      <td>xoshayzers</td>\n",
       "      <td>@tiffanylue i know  i was listenin to bad habi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1956967666</td>\n",
       "      <td>sadness</td>\n",
       "      <td>wannamama</td>\n",
       "      <td>Layin n bed with a headache  ughhhh...waitin o...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     tweet_id sentiment      author  \\\n",
       "0  1956967341     empty  xoshayzers   \n",
       "1  1956967666   sadness   wannamama   \n",
       "\n",
       "                                             content  \n",
       "0  @tiffanylue i know  i was listenin to bad habi...  \n",
       "1  Layin n bed with a headache  ughhhh...waitin o...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Explore data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop('author',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'boredom', 'fun', 'relief', 'neutral', 'happiness', 'anger', 'worry', 'sadness', 'surprise', 'love', 'hate', 'enthusiasm', 'empty'}\n",
      "13\n"
     ]
    }
   ],
   "source": [
    "#the total emotions\n",
    "print(set(data.sentiment))\n",
    "print(len(set(data.sentiment)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "#dropping some of the emotions\n",
    "data = data.drop(data[data.sentiment == 'empty'].index)\n",
    "data = data.drop(data[data.sentiment == 'boredom'].index)\n",
    "data = data.drop(data[data.sentiment == 'fun'].index)\n",
    "data = data.drop(data[data.sentiment == 'worry'].index)\n",
    "data = data.drop(data[data.sentiment == 'relief'].index)\n",
    "data = data.drop(data[data.sentiment == 'enthusiasm'].index)\n",
    "data = data.drop(data[data.sentiment == 'surprise'].index)\n",
    "data = data.drop(data[data.sentiment == 'neutral'].index)\n",
    "data = data.drop(data[data.sentiment == 'hate'].index)\n",
    "data = data.drop(data[data.sentiment == 'love'].index)\n",
    "data = data.drop(data[data.sentiment == 'anger'].index)\n",
    "print(len(set(data.sentiment)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1956967666</td>\n",
       "      <td>sadness</td>\n",
       "      <td>Layin n bed with a headache  ughhhh...waitin o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1956967696</td>\n",
       "      <td>sadness</td>\n",
       "      <td>Funeral ceremony...gloomy friday...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1956968487</td>\n",
       "      <td>sadness</td>\n",
       "      <td>I should be sleep, but im not! thinking about ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1956969035</td>\n",
       "      <td>sadness</td>\n",
       "      <td>@charviray Charlene my love. I miss you</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1956969172</td>\n",
       "      <td>sadness</td>\n",
       "      <td>@kelcouch I'm sorry  at least it's Friday?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     tweet_id sentiment                                            content\n",
       "1  1956967666   sadness  Layin n bed with a headache  ughhhh...waitin o...\n",
       "2  1956967696   sadness                Funeral ceremony...gloomy friday...\n",
       "6  1956968487   sadness  I should be sleep, but im not! thinking about ...\n",
       "8  1956969035   sadness            @charviray Charlene my love. I miss you\n",
       "9  1956969172   sadness         @kelcouch I'm sorry  at least it's Friday?"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### pre process the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make all lower case\n",
    "data['content'] = data['content'].apply(lambda x: \"\".join(x.lower() for x in x.split()))\n",
    "\n",
    "#remve punctuations\n",
    "data['content'] = data['content'].str.replace('[^\\w\\s]',' ')\n",
    "\n",
    "#remove stop words\n",
    "from nltk.corpus import stopwords\n",
    "stop = stopwords.words('english')\n",
    "data['content'] = data['content'].apply(lambda x: \" \".join(x for x in x.split() if x not in stop))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lemmatisation - convert the words to root form\n",
    "\n",
    "from textblob import Word\n",
    "\n",
    "data['content'] = data['content'].apply(lambda x: \" \".join([Word(word).lemmatize() for word in x.split()]))\n",
    "\n",
    "#correcting letter repetitions\n",
    "import re\n",
    "def de_repeat(text):\n",
    "    pattern = re.compile(r\"(.)\\1{2,}\")\n",
    "    return pattern.sub(r\"\\1\\1\", text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find unique words in the data- top 10,000 words and delete the rest\n",
    "freq = pd.Series(' '.join(data['content']).split()).value_counts()[-10000:]\n",
    "\n",
    "freq = list(freq.index)\n",
    "data['content'] = data['content'].apply(lambda x: \" \".join(x for x in x.split() if x not in freq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1956967666</td>\n",
       "      <td>sadness</td>\n",
       "      <td>layinnbedwithaheadacheughhhh waitinonyourcall</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1956967696</td>\n",
       "      <td>sadness</td>\n",
       "      <td>gloomyfriday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1956968487</td>\n",
       "      <td>sadness</td>\n",
       "      <td>ishouldbesleep butimnot buthe damn amp hewantsme2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1956969035</td>\n",
       "      <td>sadness</td>\n",
       "      <td>charviraycharlenemylove imissyou</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1956969172</td>\n",
       "      <td>sadness</td>\n",
       "      <td>kelcouchi sfriday</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     tweet_id sentiment                                            content\n",
       "1  1956967666   sadness      layinnbedwithaheadacheughhhh waitinonyourcall\n",
       "2  1956967696   sadness                                       gloomyfriday\n",
       "6  1956968487   sadness  ishouldbesleep butimnot buthe damn amp hewantsme2\n",
       "8  1956969035   sadness                   charviraycharlenemylove imissyou\n",
       "9  1956969172   sadness                                  kelcouchi sfriday"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#one hot encoding for the labels \n",
    "from sklearn import preprocessing\n",
    "lbl_enc = preprocessing.LabelEncoder()\n",
    "y = lbl_enc.fit_transform(data.sentiment.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 ... 0 0 0] ['sadness' 'sadness' 'sadness' ... 'happiness' 'happiness' 'happiness']\n"
     ]
    }
   ],
   "source": [
    "print(y, data.sentiment.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split into training and test data \n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_val, y_train, y_val = train_test_split(data.content.values, y, random_state=42, test_size=0.3, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extracting tf-idf parameters\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf = TfidfVectorizer(max_features=1000, analyzer='word',ngram_range=(1,3))\n",
    "\n",
    "X_train_tfidf = tfidf.fit_transform(X_train)\n",
    "X_val_tfidf = tfidf.fit_transform(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#transform the words into array to get the number of times a word appears\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "count_vect = CountVectorizer(analyzer='word')\n",
    "count_vect.fit(data['content'])\n",
    "X_train_count =  count_vect.transform(X_train)\n",
    "X_val_count =  count_vect.transform(X_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.5929971088981689\n"
     ]
    }
   ],
   "source": [
    "## Train the model\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import SGDClassifier \n",
    "\n",
    "lsvm = SGDClassifier(alpha=0.001, random_state=5, max_iter=15, tol=None)\n",
    "lsvm.fit(X_train_count, y_train)\n",
    "y_pred = lsvm.predict(X_val_count)\n",
    "print('accuracy %s' % accuracy_score(y_pred, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = pd.DataFrame(['I am very happy today! The atmosphere looks cheerful',\n",
    "'Things are looking great. It was such a good day',\n",
    "'Success is right around the corner. Lets celebrate this victory',\n",
    "'Everything is more beautiful when you experience them with a smile!',\n",
    "'Now this is my worst, okay? But I am gonna get better.',\n",
    "'I am tired, boss. Tired of being on the road, lonely as a sparrow in the rain. I am tired of all the pain I feel',\n",
    "'This is quite depressing. I am filled with sorrow',\n",
    "'His death broke my heart. It was a sad day'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = 'This is quite depressing. I am filled with sorrow'\n",
    "tweets = pd.DataFrame([text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\n"
     ]
    }
   ],
   "source": [
    "# Doing some preprocessing on these tweets as done before\n",
    "tweets[0] = tweets[0].str.replace('[^\\w\\s]',' ')\n",
    "from nltk.corpus import stopwords\n",
    "stop = stopwords.words('english')\n",
    "tweets[0] = tweets[0].apply(lambda x: \" \".join(x for x in x.split() if x not in stop))\n",
    "from textblob import Word\n",
    "tweets[0] = tweets[0].apply(lambda x: \" \".join([Word(word).lemmatize() for word in x.split()]))\n",
    "# Extracting Count Vectors feature from our tweets\n",
    "tweet_count = count_vect.transform(tweets[0])\n",
    "#Predicting the emotion of the tweet using our already trained linear SVM\n",
    "tweet_pred = lsvm.predict(tweet_count)\n",
    "print(tweet_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (tweet_pred == [0]):\n",
    "    emotion = \"sadness\"\n",
    "else:\n",
    "    emotion = \"happiness\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the tweet for the tacotron model to convert it to speech\n",
    "import pickle\n",
    "file_name = \"tweet\"\n",
    "with open(file_name,'wb') as my_file_obj:\n",
    "    pickle.dump(text, my_file_obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = \"emotion_detected\"\n",
    "with open(file_name,'wb') as my_file_obj:\n",
    "    pickle.dump(emotion, my_file_obj)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
